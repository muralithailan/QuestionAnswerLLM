{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9729cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq datasets==2.12.0 qdrant-client==1.2.0 sentence-transformers==2.2.2 torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b97a4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c008d9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4c71c4410b4b33ab89dbdbb8f973c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445f537f491948cc9cd3b576bd4d1e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d429681af78348ea90b113e875a73f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset duorc/ParaphraseRC to /Users/balamurali/.cache/huggingface/datasets/duorc/ParaphraseRC/1.0.0/7a96356b7615d573abcd03a9328292c38348547971989538a771c32089bff199...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e7a34262644f478db6fe17f33dc8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e6ff490f644e91a8da9ab179b1e674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004e45629850494693c54604957941a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.49M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803575a71df144909b75db565e7a1e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad392f2e3bdb4a3286756a1a4f2e2cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/69524 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/15591 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/15857 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset duorc downloaded and prepared to /Users/balamurali/.cache/huggingface/datasets/duorc/ParaphraseRC/1.0.0/7a96356b7615d573abcd03a9328292c38348547971989538a771c32089bff199. Subsequent calls will reuse this data.\n",
      "Before removing duplicates: 69524\n",
      "Unique Plots: 5133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Set in the second half of the 22nd century, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Noriko's Dinner Table</td>\n",
       "      <td>The film starts on December 12th, 2001 with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Gutterballs</td>\n",
       "      <td>A brutally sadistic rape leads to a series of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>An Innocent Man</td>\n",
       "      <td>Jimmie Rainwood (Tom Selleck) is a respected m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>Every hundred years, the evil Morgana (Kelly L...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title   \n",
       "0               Ghosts of Mars  \\\n",
       "15       Noriko's Dinner Table   \n",
       "34                 Gutterballs   \n",
       "83             An Innocent Man   \n",
       "105  The Sorcerer's Apprentice   \n",
       "\n",
       "                                                  plot  \n",
       "0    Set in the second half of the 22nd century, Ma...  \n",
       "15   The film starts on December 12th, 2001 with a ...  \n",
       "34   A brutally sadistic rape leads to a series of ...  \n",
       "83   Jimmie Rainwood (Tom Selleck) is a respected m...  \n",
       "105  Every hundred years, the evil Morgana (Kelly L...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the duorc dataset into a pandas dataframe\n",
    "df = load_dataset(\"duorc\", \"ParaphraseRC\", split=\"train\").to_pandas()\n",
    "df = df[[\"title\", \"plot\"]]  # select only title and plot column\n",
    "print(f\"Before removing duplicates: {len(df)}\")\n",
    "\n",
    "df = df.drop_duplicates(subset=\"plot\")  # drop rows containing duplicate plot passages, if any\n",
    "print(f\"Unique Plots: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c728cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\":memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348e089",
   "metadata": {},
   "source": [
    "Now we create a new collection called extractive-question-answering — we can name the collection anything we want.\n",
    "\n",
    "We specify the metric type as \"cosine\" and dimension or size as 384 because the retriever we use to generate context embeddings is optimized for cosine similarity and outputs 384-dimension vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50317b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[]\n",
      "collections=[CollectionDescription(name='extractive-question-answering')]\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"extractive-question-answering\"\n",
    "\n",
    "collections = client.get_collections()\n",
    "print(collections)\n",
    "\n",
    "# only create collection if it doesn't exist\n",
    "if collection_name not in [c.name for c in collections.collections]:\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=384,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    )\n",
    "collections = client.get_collections()\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8dd741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27002ccfeff44aa497aac830bbf43cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5fedf/.gitattributes:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb30e24d211c460ea890bf01566df4a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a189fc835245eb8bdb1e55c0edf115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)2cb455fedf/README.md:   0%|          | 0.00/11.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20c0268bbc54651b54e385f15bfc69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b455fedf/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6007d0f2bd2c4da4b1c5887ce91f5181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478f0eb45d6b4763ac48fcb7ee054005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)edf/data_config.json:   0%|          | 0.00/25.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072de62682dc450d89e3bf73d114cfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e52cf073bd45cb8d0cce6bc1b4cd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b46038c037c42f8bf2f857a9e8a3777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56b883a366748bfb5bce7164276fe2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5fedf/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d560e9d7cc07457d847dcdb32b22951a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/383 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fa45a71db34747bd7c6d1f15f40feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fedf/train_script.py:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf6c976441041b0b8e666f6d5d5dea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)2cb455fedf/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325221c688f7429ab26fbdfc4da0d51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)455fedf/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set device to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# load the retriever model from huggingface model hub\n",
    "retriever = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\", device=device)\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3be148",
   "metadata": {},
   "source": [
    "## Generate Embeddings -> Store in Qdrant\n",
    "\n",
    "Next, we need to generate embeddings for the context passages. We will use the `retriever.encode` for that. \n",
    "\n",
    "When passing the documents to Qdrant, we need an:\n",
    "1. id (a unique integer value), \n",
    "2. context embedding, and \n",
    "3. payload for each document representing context passages in the dataset. The payload is a dictionary containing data relevant to our embeddings, such as the title, plot etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39490d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b914cb83ebd143b1a0b8b24b3c286364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector count in collection: 5133\n",
      "CPU times: user 13min 33s, sys: 3min 24s, total: 16min 57s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 512  # specify batch size according to your RAM and compute, higher batch size = more RAM usage\n",
    "\n",
    "for index in tqdm(range(0, len(df), batch_size)):\n",
    "    i_end = min(index + batch_size, len(df))  # find end of batch\n",
    "    batch = df.iloc[index:i_end]  # extract batch\n",
    "    emb = retriever.encode(batch[\"plot\"].tolist()).tolist()  # generate embeddings for batch\n",
    "    meta = batch.to_dict(orient=\"records\")  # get metadata\n",
    "    ids = list(range(index, i_end))  # create unique IDs\n",
    "\n",
    "    # upsert to qdrant\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=models.Batch(ids=ids, vectors=emb, payloads=meta),\n",
    "    )\n",
    "\n",
    "collection_vector_count = client.get_collection(collection_name=collection_name).vectors_count\n",
    "print(f\"Vector count in collection: {collection_vector_count}\")\n",
    "assert collection_vector_count == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8d66a",
   "metadata": {},
   "source": [
    "## Initialize Reader\n",
    "\n",
    "We use the `bert-large-uncased-whole-word-masking-finetuned-squad` model from the HuggingFace model hub as our reader model. This is finetuned on the [SQuAD dataset](https://rajpurkar.github.io/SQuAD-explorer/). It is trained to extract an answer from a given context. This special mechanism is why we can use this model to extract answers from our context passages. \n",
    "\n",
    "This is our (encoder) component which uses the contexts to extract an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fda98be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a8d89296ed4e058236d4f284aadcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c153e69dec4e899cd88b8cf837870e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1aba3cb8ed431dbc8c90518e201a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c385926d1dd04676a86ecf986d25d7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6e1d179f6142dfac2e79b5c9b513f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForQuestionAnswering(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 1024)\n",
      "      (token_type_embeddings): Embedding(2, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
      ") <transformers.pipelines.question_answering.QuestionAnsweringPipeline object at 0x2ec33ee30>\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "# load the reader model into a question-answering pipeline\n",
    "reader = pipeline(\"question-answering\", model=model_name, tokenizer=model_name)\n",
    "print(reader.model, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57cf7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_plot(question: str, top_k: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get the relevant plot for a given question\n",
    "\n",
    "    Args:\n",
    "        question (str): What do we want to know?\n",
    "        top_k (int): Top K results to return\n",
    "\n",
    "    Returns:\n",
    "        context (List[str]):\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoded_query = retriever.encode(question).tolist()  # generate embeddings for the question\n",
    "\n",
    "        result = client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=encoded_query,\n",
    "            limit=top_k,\n",
    "        )  # search qdrant collection for context passage with the answer\n",
    "\n",
    "        context = [\n",
    "            [x.payload[\"title\"], x.payload[\"plot\"]] for x in result\n",
    "        ]  # extract title and payload from result\n",
    "        return context\n",
    "\n",
    "    except Exception as e:\n",
    "        print({e})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eae9eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Three Idiots',\n",
       "  'Farhan Qureshi (R. Madhavan), Raju Rastogi (Sharman Joshi), and Rancchoddas \"Rancho\" Shyamaldas Chanchad (Aamir Khan) are three engineering students who share a room in a hostel at the Imperial College of Engineering, one of the best colleges in India. While Farhan and Raju are average students from modest backgrounds, Rancho is from a rich family. Farhan wants to become a wildlife photographer, but has joined engineering college to fulfil his father\\'s wish. Raju on the other hand wants to uplift his family fortunes. Rancho is a wealthy genius who studies for the sheer joy of it. However, Rancho\\'s passion is for knowledge and taking apart and building machines rather than the conventional obsession of the other students with exam ranks. With his different approach Rancho incurs the wrath of dean of college, Professor Viru Sahastrabudhhe (ViruS) (Boman Irani). Rancho irritates his lecturers by giving creative and unorthodox answers, and confronts ViruS after fellow student Joy Lobo hangs himself in his dormitory room. Joy had requested an extension on his major project on compassionate groundshis father had suffered a strokebut ViruS refused, saying that he himself was completely unmoved by his own son\\'s accidental death after being hit by a train. Rancho denounces the rat race, dog-eat-dog, mindless rote learning mentality of the institution, blaming it for Lobo\\'s death.Threatened by Rancho\\'s talent and free spirit, ViruS labels him an \"idiot\" and attempts on a number of occasions to destroy his friendship with Farhan and Raju, warning them and their parents to steer clear of Rancho. In contrast, ViruS model student is Chatur Ramalingam or \"Silencer\", (Omi Vaidya) who sees a high rank at the prestigious college as his ticket to higher social status, corporate power, and therefore wealth. Chatur conforms to the expectations of the system. Rancho humiliates Chatur, who is awarded the honour of making a speech at an award ceremony, by substituting obscenities into the text, which has been written by the librarian. As expected, Chatur mindlessly memorises the speech, without noticing that anything is amiss, partly aided by his lack of knowledge on Hindi. His speech becomes the laughing stock of the audience, infuriating the authorities in the process.Meanwhile, Rancho also falls in love with ViruS\\' medical student daughter Pia (Kareena Kapoor) when he, Raju and Farhan crash her sister\\'s wedding banquet in order to get a free meal, in the process further infuriating ViruS.Meanwhile, the three students continue to anger ViruS, although Rancho continues to come first in every exam, while Chatur is always second, and Farhan and Raju are inevitably in the last two positions. The tensions come to a head when the three friends, who are already drunk, break into ViruS\\'s house at night to allow Rancho to propose to Pia, and then urinate on a door inside the compound before running away when ViruS senses intruders. The next day, ViruS threatens to expel Raju lest he talks on the other two. Unable to choose between betraying his friend or letting down his family, Raju jumps out of the 3rd floor window and lands on a courtyard, but after extensive care from Pia and his roommates, awakes from a coma.The experience has changed Farhan and Raju, and they adopt Rancho\\'s outlook. Farhan decides to pursue his love of photography, while Raju takes an unexpected approach for an interview for a corporate job. He attends in plaster and a wheelchair and gives a series of non-conformal and frank answers. However, ViruS is unsympathetic and vows to make the final exam as hard as possible so that Raju is unable to graduate. Pia hears him and angrily confronts him, and when ViruS gives the same ruthless reply he gives to his students, she denounces him in the same way that Rancho did over the suicide of Lobo. Pia reveals that Viru\\'s son and her brother was not killed in an accident but committed suicide in front of a train and left a letter because ViruS had forced him to pursue a career in engineering over his love for literature; ViruS always mentioned that he unsympathetically failed his son on the ICE entrance exams over and over to every new intake of ICE students. After this, Pia walks out on the family home, and takes ViruS\\'s spare keys with her. She tells Rancho of the exam, and he and Farhan break into ViruS\\'s office and steals the exam and give it to Raju, who with his new-found attitude, is unconcerned with the prospect of failing, and refuses to cheat and throws the paper away. However, ViruS catches the trio and expels them on the spot. However, they earn a reprieve when Viru\\'s pregnant elder daughter Mona (Mona Singh) goes into labour at the same time. A heavy storm cuts all power and traffic, and Pia is still in self-imposed exile, so she instructs Rancho to deliver the baby in the college common room via VOIP, after Rancho restores power using car batteries and a power inverter that Rancho had dreamed up and ViruS had mocked. Rancho then delivers the baby with the help of a cobbled-together Vacuum extractor.After the baby is apparently stillborn, Rancho resuscitates it. ViruS reconciles with Rancho and his friends and allows them to take their final exams and they graduate. Rancho comes first and is awarded ViruS\\'s pen, which the professor had been keeping for decades before finding a brilliant enough student to gift it to.Their story is framed as intermittent flashbacks from the present day, ten years after Chatur vowed revenge on Rancho for embarrassing him at the speech night and promised to become more successful than Rancho a decade later. Having lost contact with Rancho, who disappeared during the graduation party and went into seclusion, Raju and Farhan begin a journey to find him. They are joined by Chatur, now a wealthy and successful businessman, who joins them, brazenly confident that he has surpassed Rancho. Chatur is also looking to seal a deal with a famous scientist and prospective business associate named Phunsukh Wangdu. Chatur sees Wangdu, who has hundreds of patents, as his ticket to further social prestige. When they find Rancho\\'s house, they walk into his father\\'s funeral, and find a completely different Rancho Jaaved Jaffrey. After accusing the new man of stealing their friend\\'s identity and profiting from his intellect, the host pulls a gun on them, but Farhan and Raju turn the tables by seizing the father\\'s ashes and threatening to flush them down the toilet. The householder capitulates and says that their friend was a destitute servant boy who loved learning, while he, the real Rancho, was a lazy wealthy child who disliked study, so the family agreed to let the servant boy study in Rancho\\'s place instead of labouring. In return, the real Rancho would pocket the qualifications and the benefits thereof, while the impersonator would sever all contact with the world and start a new life. The real Rancho reveals that his impersonator is now a schoolteacher in Ladakh.Raju and Farhan then find Pia, and take her from her wedding day to Suhas by performing the same tricks with his material possessions, and having Raju turn up to the ceremony disguised as the groom and eloping with Pia in public. When they arrive in Ladakh, they see a group of enthusiastic Ladakhi children who are motivated by love of knowledge. Pia and the fake Rancho rekindle their love, while Chatur mocks and abuses Rancho the schoolteacher before walking away. When his friends ask what his real name is, he reveals that it Phunsukh Wangdu and phones Chatur, who has turned his back, to turn around and meet his prospective business partner. Chatur is horrified and falls to his knees, accepts his defeat and continues to plead his case with Phunsukh to establish the business relationship he was after.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_answer(question: str, context: List[str]):\n",
    "    \"\"\"\n",
    "    Extract the answer from the context for a given question\n",
    "\n",
    "    Args:\n",
    "        question (str): _description_\n",
    "        context (list[str]): _description_\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for c in context:\n",
    "        # feed the reader the question and contexts to extract answers\n",
    "        answer = reader(question=question, context=c[1])\n",
    "\n",
    "        # add the context to answer dict for printing both together, we print only first 500 characters of plot\n",
    "        answer[\"title\"] = c[0]\n",
    "        results.append(answer)\n",
    "\n",
    "    # sort the result based on the score from reader model\n",
    "    sorted_result = sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
    "    for i in range(len(sorted_result)):\n",
    "        print(f\"{i+1}\", end=\" \")\n",
    "        print(\n",
    "            \"Answer: \",\n",
    "            sorted_result[i][\"answer\"],\n",
    "            \"\\n  Title: \",\n",
    "            sorted_result[i][\"title\"],\n",
    "            \"\\n  score: \",\n",
    "            sorted_result[i][\"score\"],\n",
    "        )\n",
    "\n",
    "\n",
    "question = \"In the movie 3 Idiots, what is the name of the college where the main characters Rancho, Farhan, and Raju study\"\n",
    "context = get_relevant_plot(question, top_k=1)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38e23a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Answer:  Imperial College of Engineering \n",
      "  Title:  Three Idiots \n",
      "  score:  0.9049272537231445\n"
     ]
    }
   ],
   "source": [
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "154ee75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Explain movie Jeepers Creepers II\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f27f0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Jeepers Creepers II',\n",
       "  'Three days after the events of the first film, a young boy named Billy Taggart helps his father, Jack Taggart Sr., erect scarecrows in a cornfield. As Billy makes his way through the field, the Creeper, disguised as one of the scarecrows, abducts him in front of Taggart and Billy\\'s older brother, Jack Jr. The following day, a school bus carrying a high school basketball team and cheerleaders suffers a blowout. The chaperones inspect the tire and find it torn apart by a hand-crafted shuriken seemingly constructed from fragments of bone. Back on the Taggart farm, Jack finds a dagger dropped by the Creeper. Upon showing it to his father, the weapon inexplicably flies out of his hand on its own accord.\\nOn the bus, cheerleader Minxie has a vision of Billy and Darry Jenner, the Creeper\\'s victim from the first film, who both attempt to warn her about the Creeper. The Creeper then blows out another tire, disabling the bus. With the party stranded, the Creeper attacks, abducting the coaches and the bus driver. After unsuccessfully attempting to enter the bus, it singles out Minxie and some of the other occupants: Dante, Jake, Scotty, Bucky, and especially Double D. Eventually, Minxie collapses and has another vision in which Darry explains the Creeper\\'s nature: that every twenty-third spring, for twenty-three days, it emerges from hibernation and hunts for victims, from whom it selects specific organs and body parts which it then consumes in order to replace those of its own.\\nAfter hearing numerous police reports, which imply that the authorities are aware of what is going on, the Taggarts decide to investigate. After Taggart establishes radio contact with the students, the Creeper resumes its attack and kills Dante, using his severed head as a replacement for its own. The students leave the bus, and the Creeper chases them across a field, killing Jake and taking Scotty. During the chaos, Taggart and Jack intervene, but both parties\\' vehicles are destroyed. The Creeper attacks Double D as he attempts to escape in another vehicle. The car is intentionally crashed, wounding both the Creeper and Double D. Before the Creeper can eat Double D, Taggart, Jack, and the other students arrive and shoot it in the head with the harpoon, while Taggart repeatedly stabs it. Before it can die, the Creeper goes back into hibernation.\\nTwenty-three years later, a group of teenagers drive to Taggart\\'s farm, where the Creeper is a sideshow attraction. They notice Taggart watching it with a harpoon gun at his side. When they ask him if he is waiting for something, Taggart looks up at the Creeper and says, \"About three more days, give or take a day or two.\"'],\n",
       " ['Vampires Vs. Zombies',\n",
       "  'Nightmare[edit]\\nThe movie begins with a scene showing a sleeping girl being menaced by a female vampire in her bedroom. The dream is abandoned when the sleeping girl wakes up screaming in the front seat of her father\\'s forest green Jeep Cherokee. She then tells her father that she has had \"the same dream again\".\\nSpeeding Crash[edit]\\nJenny and her father, Travis, who is at the helm of said forest green Jeep Cherokee, are driving at a steady 5 miles per hour, to an undisclosed location. Suddenly there is an incident. Jenny yells out \"DAD!\" as the jeep proceeds to plow over a zombie dressed up like a roadside construction worker. The zombie\\'s head goes flying skyward immediately following the impact, though its body still shows a head visibly attached. The audience is then treated to a techno rave ballad as the jeep fades from view, and the beginning credits roll.\\nZombie Hell[edit]\\nA radio news reporter describes a recent and horrific epidemic of zombiedom that has swept the calm countryside of the once peaceful set of woods with one road and a gas station. The reports indicate that a symptom of said outbreak is \"murder\". They then pull up beside a stalled car with three occupants: an older woman and two younger women- one of whom is bound and gagged. Ignoring the bound and gagged girl, Travis gives the other girl a lift. This girl is possibly a vampire named Carmilla, or possibly not. This is followed by a very long sequence at a roadside gas-station in which a strange woman in gothic make-up (possibly a witch or sorceress) hands them a necklace.\\nChecking into the Madhouse[edit]\\nAs the gas-station attendant (played by producer Rob Carpenter) gets sucked into an orgy of violence at the hands of vampires/zombies, Travis, his daughter Jenny, and Carmilla drive off, only to break down further down the road. They are stranded for hours until a guy in a Land Rover drives up. As the driver is turning into a vampire, Travis kills him and uses some of his supplies to fix the jeep. He lets Jenny and Carmilla steal the Land Rover. As Travis drives ahead in the jeep, Carmilla and Jenny indulge in lesbian sex in the commandeered Land Rover. The destination is the original crypt Carmilla had been buried in. Flashbacks of a madhouse emerge, where Carmilla is revealed to be a nurse, and Jenny her insane patient. Later, they make their way to the crypt, where they encounter more zombies/vampires. After the true reality of the situation is revealed, they check into a motel. Bright-red stage blood flows in these gory and surreal scenes, which could be delusional or possibly flash-backs. There is also a vampire-hunter known as \\'The General\\' who may be pursuing them, or possibly, arranging a rendezvous, due to his daughter being kidnapped by a female colleague of Carmilla.\\nThe film ends with a spinning book and the words, The End.']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = get_relevant_plot(question, top_k=2)\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "788b80a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Answer:  Jenny her insane patient. Later, they make their way to the crypt \n",
      "  Title:  Vampires Vs. Zombies \n",
      "  score:  0.0009691474842838943\n",
      "2 Answer:  first film \n",
      "  Title:  Jeepers Creepers II \n",
      "  score:  1.1143445590278134e-05\n"
     ]
    }
   ],
   "source": [
    "extract_answer(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26198957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
